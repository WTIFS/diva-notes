# 架构

![图片](assets/640.png)



`topic` 是一个逻辑上的概念，不是一个实体。一个 `topic` 包含多个 `partition`，`partition` 分布在多台机器上。这个机器，`kafka` 中称之为 `broker`。

对于一个 `topic`，可以有多个不同的消费组同时进行消费。一个消费组内部可以有多个消费者实例，这样可以提高消费速率。



但是一个 `partition` 只能被消费组中的一个消费者实例来消费。换句话说，消费组中如果有多个消费者，不能够存在两个消费者同时消费一个 `partition` 的场景。应为两个同组消费者消费同一个 `partition`，会出现乱序的情况。





# 存储

每个 `topic` 的每个 `partition` 在磁盘上对应一个文件夹，该文件夹下存储这个 `partition` 的所有消息和索引文件，目录名就是 `topic-partition`，比如 `topic` 为 `asdf` 的第一个分区，就是 `asdf-1`。

每条消息以磁盘顺序写的方式追到到文件末尾，因此写入速度极快。



### 消息结构

`kafka` 自己实现了一套协议，在 `tcp` 层之上，消息结构如下：

```go
type Message struct {
	offset      int64      // 偏移量
	MessageSize int32      // 消息大小
	data        MessageSet // 消息体
}

type MessageSet struct {
    CRC         int32      // 校验码
    MagicByte   int8       // 版本，向后兼容，没用
    Attributes  int8       // 元数据，包含压缩方式
    Key         []byte
    Value       []byte
}
```



`kafka` 的消费如果只是移动游标并不删除数据，那么随着时间的推移数据肯定会把磁盘打满，这个问题该如何解决呢？这就涉及到 `kafka` 的消息过期机制，类似于 `redis` 中的 `expire`。

假如所有消息都写入一个文件，很快这个文件就到 `200G` 了。现在告诉你，这个文件前 `X` 行过期失效了，你应该怎么删除呢？非常难办，这和让你删除一个数组中的前  `N` 个元素一样，需要把后续的元素向前移动，这涉及到大量的 `CPU copy` 操作，删除的代价非常大。



### 分段

因此，`kafka` 在实际存储 `partition` 时又进行了一个拆分。每个 `parition` 的数据并不是写到一个文件里，而是写到多个 `segment` 文件里。假如设置的一个 `segment` 文件大小上限是 `100M`，写满就会创建新的 `segment` 文件，后续的消息就写到新创建的 `segment` ，就像我们业务系统的日志文件切割一样。这样做的好处是，当 `segment` 中所有消息都过期时，可以很容易地直接删除整个文件。而由于`segment` 中消息是有序的，看是否都过期就看最后一条是否过期就行了。



### 索引 

数据文件分段使得可以在一个较小的数据文件中查找对应 `offset` 的消息了，但是这依然需要顺序扫描才能找到对应 `offset` 的消息。

为了进一步提高查找的效率，`kafka` 为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，也标记了起始 `offset` ，只是文件扩展名为 `.index`。

另外 `index` 文件中并没有为数据文件中的每条消息建立索引，而是采用了稀疏存储的方式，每隔一部分的数据才建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。



### 查找

1. 首先是用二分查找确定它是在哪个 `Segment` 中
2. 打开这个 `Segment` 的 `index` 文件，也是用二分查找找到 `offset` 小于或者等于要查找的 `offset` 的索引条目中最大的那个 `offset`
3. 打开数据文件，从第2步找到的 `offset` 顺序扫描直到找到要查找的 `offset`





#### 参考
> [平凡之路无尽路 - Kafka的message存储数据结构](https://blog.csdn.net/gududedabai/article/details/80001523)

