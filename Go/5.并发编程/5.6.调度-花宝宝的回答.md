[goroutine](https://zhida.zhihu.com/search?content_id=768043204&content_type=Answer&match_order=1&q=goroutine&zhida_source=entity)不是线程。

很多人以为goroutine就是Go的”轻量级线程”，实际上它压根不是线程，只是被调度到线程上执行的一段代码。

**线程是操作系统管的，goroutine是[Go runtime](https://zhida.zhihu.com/search?content_id=768043204&content_type=Answer&match_order=1&q=Go+runtime&zhida_source=entity)管的。**

一个Go程序可以开几十万个goroutine，但操作系统只看到几个线程在跑。goroutine在用户态调度，线程在内核态调度。这就是为什么goroutine能这么轻量。

创建一个线程，操作系统要分配1MB的栈空间，还要在内核态记录一堆状态。创建一个goroutine，Go runtime只分配2KB栈空间，其他啥也不用干。

2KB对1MB，500倍的差距。

这就是为什么你开10万个线程机器直接炸，开10万个goroutine啥事没有。

**动态栈才是关键**

2KB栈够用吗？大部分时候够，不够的时候自动扩容。

goroutine的栈不是固定的，初始2KB，用完了就扩。扩的时候runtime会分配一块新的更大的栈空间，把旧栈的数据拷过去，然后继续跑。

这个过程你感觉不到，代码里完全无感。

线程的栈是固定的，创建的时候就分配好1MB，你用不完也得占着。10万个线程就是100GB内存，根本扛不住。

goroutine的栈是按需分配的，10万个goroutine如果每个只用2KB，那就20MB。实际上可能会扩到几十KB，但也就几个GB，完全可接受。

**[GMP模型](https://zhida.zhihu.com/search?content_id=768043204&content_type=Answer&match_order=1&q=GMP模型&zhida_source=entity)**

goroutine的调度靠三个东西：G、M、P。

**G（Goroutine）**：就是你写的那个`go func()`，一段要执行的代码。

**M（Machine）**：操作系统线程，真正在CPU上跑的东西。

**P（Processor）**：逻辑处理器，可以理解为”执行槽位”。一个P持有一个goroutine的本地队列，决定哪个G能在哪个M上跑。

P的数量默认等于CPU核心数，可以通过`GOMAXPROCS`调整。

举个例子，你的机器是8核CPU，那就有8个P。每个P绑定一个M（线程），每个M从P的本地队列里取G来执行。

流程是这样的：

1. 你写了`go func()`，创建一个G，扔到某个P的本地队列里
2. 某个M绑定到这个P，从队列里拿出G，开始执行
3. G执行完了，M继续从P的队列里拿下一个G
4. 如果P的队列空了，M会去其他P的队列里”偷”G过来执行（[work-stealing](https://zhida.zhihu.com/search?content_id=768043204&content_type=Answer&match_order=1&q=work-stealing&zhida_source=entity)）

这套机制的核心就是**用户态调度**。

操作系统不知道goroutine的存在，它只看到几个线程在跑。goroutine之间的切换不需要进入内核态，不需要保存和恢复一大堆寄存器状态，切换成本极低。

线程切换要进内核，保存现场，恢复现场，光这一套流程就得几千个CPU时钟周期。goroutine切换在用户态搞定，几十个时钟周期就行。

**调度的时机**

goroutine什么时候会被切换？

1. **主动让出**：你调用了`runtime.Gosched()`，goroutine主动让出CPU
2. **IO操作**：读网络、读文件，goroutine会被挂起，等IO好了再唤醒
3. **channel操作阻塞**：往满的channel写，从空的channel读，都会挂起
4. **系统调用**：调用了系统调用，goroutine所在的M会和P解绑，P可以去调度别的G
5. **抢占**：Go 1.14之后加入了异步抢占，长时间运行的goroutine会被强制切换

前面几种都好理解，最后一个”抢占”是个大坑。

早期版本的Go，如果一个goroutine里跑了个死循环，它会一直占着P不放，其他goroutine饿死。

```text
go func() {
    for {
        // 啥也不干，就是循环
    }
}()
```

早期版本的Go，这个goroutine会把一个P占住不放，因为它没有任何让出CPU的操作。后来Go加入了基于信号的异步抢占，runtime会定时发信号强制切换。

但这个机制也不是万能的。在某些极端情况下，比如纯CPU密集计算且不调用任何函数，还是可能卡住。不过一般代码不会这么写。

**work-stealing**

假设有8个P，某个P的本地队列里有100个G在排队，其他P的队列都空了。

这时候其他P绑定的M就会去这个忙的P的队列里”偷”一半G过来，自己执行。

这个机制叫work-stealing，保证所有P的负载尽量均衡。

但有个细节：偷的时候从队列尾部偷，而本地P自己从队列头部取。这样设计是为了减少锁竞争。

还有一个全局队列。如果P的本地队列满了，新的G会扔到全局队列。如果所有P的本地队列都空了，才会去全局队列拿。

全局队列的优先级比work-stealing低，因为访问全局队列需要加锁，开销更大。

**系统调用的处理**

goroutine里调了个系统调用，比如读文件，这时候会发生什么？

系统调用会阻塞线程，但不能让P也闲着。

Go的做法是：M和P解绑，M去执行系统调用，P找个新的M绑定，继续调度其他G。

等系统调用返回了，M尝试重新绑定到P。如果原来的P已经被别的M占了，这个M就去抢别的空闲P，实在没有就把G扔回全局队列，M自己进休眠。

这样保证了系统调用不会浪费P的调度能力。

网络IO是特殊情况，Go用了[netpoller](https://zhida.zhihu.com/search?content_id=768043204&content_type=Answer&match_order=1&q=netpoller&zhida_source=entity)，基于epoll/kqueue这些机制，不会真正阻塞M。goroutine发起网络IO就被挂起，等IO就绪了runtime再唤醒它，整个过程不占用M。

**实际的坑**

理论讲完了，说几个实际会遇到的问题。

**goroutine泄漏**：goroutine一旦创建就不会自动销毁，必须执行完才会回收。如果你的goroutine卡在channel操作或者某个锁上，永远等不到数据，它就会一直占着内存不放。

```text
ch := make(chan int)
go func() {
    data := <-ch  // 如果没人往ch写，这里永远阻塞
    fmt.Println(data)
}()
```

这个goroutine永远不会结束，内存泄漏了。

**GOMAXPROCS设置**：P的数量决定了真正的并行度。默认是CPU核心数，大部分场景用默认值就够了。除非你有明确的性能瓶颈，不然别乱调。

**栈溢出**：虽然栈会自动扩容，但扩容有上限。递归太深或者分配太大的局部变量，还是会炸。不过这种情况很少见。

**panic传播**：goroutine里panic了，只会干掉这个goroutine，不会影响其他goroutine。但如果main goroutine panic了，整个程序退出。

所以创建goroutine的时候最好加个recover：

```text
go func() {
    defer func() {
        if err := recover(); err != nil {
            log.Println("goroutine panic:", err)
        }
    }()
    // 你的代码
}()
```

goroutine的实现看起来复杂，但核心就几件事：用户态调度、动态栈、GMP模型、work-stealing。

搞清楚这些，你就知道为什么Go能轻松开几十万个goroutine，为什么goroutine比线程快，为什么有些场景goroutine会卡住。