任何一个由编译型语言（不管是C，C++，go还是汇编语言）所编写的程序在被操作系统加载起来运行时都会顺序经过如下几个阶段：

1. 从磁盘上把可执行程序读入内存；
2. 创建进程和主线程；
3. 为主线程分配栈空间；
4. 把由用户在命令行输入的参数拷贝到主线程的栈；
5. 把主线程放入操作系统的运行队列等待被调度执起来运行。



# 程序启动

使用 `GDB` 调试 `Go` 程序，可以看到程序入口对应的代码文件。程序启动部分的代码是用汇编写的，以 `amd64` CPU 为例，程序的入口函数为 `runtime/rt0_linux_amd64.s`。里面依次执行如下步骤：

1. 初始化第一个 `g0、m0`。`m0` 为代表进程的主线程
1. 调用 `osinit()` 初始化系统核心数
1. 调用 `schedinit()` 初始化调度器
   1. 初始化调度器、内存分配器、堆、栈等
   1. 会创建一批 `P`，数量默认为 `CPU` 数
   1. 如果用户设置了 `GOMAXPROCS` 环境变量，则 `P` 的数量为 `max(GOMAXPROCS, 256)`，也就是最多 256
   1. 这些 `P` 初始创建好后都放置在全局变量 `Sched ` 的 `pidle` 队列里

1. 调用 `newproc()` 函数创建出第一个 `G`，这个 `goroutine` 将执行的函数是 `runtime/proc.go/main()`，该协程即为 `main goroutine`
   1. 里面创建了一个新的内核线程 `M`: 系统监控 `sysmon`
   1. 初始化、启动垃圾回收
   1. 运行我们写的 `main()` 函数

1. 调用 `mstart()` 启动 `M` 线程、运行 `main goroutine`、启动调度


`runtime/asm_amd64.s`:

```assembly
// 入口
TEXT _rt0_amd64(SB),NOSPLIT,$-8  // 定义 _rt0_amd64 这个符号
    MOVQ    0(SP), DI            // 把参数数量 argc 的地址放入 DI 寄存器
    LEAQ    8(SP), SI            // 把参数数组 argv 的地址放入 SI 寄存器
    JMP	runtime·rt0_go(SB)       // 跳转至 rt0_go


TEXT runtime·rt0_go(SB),NOSPLIT|TOPFRAME,$0

    // 初始化第一个g0、空间分配。第一个 g0 是用汇编写的
    MOVQ	$runtime·g0(SB), DI
    LEAQ	(-64*1024+104)(SP), BX // 可以看到 g0 有大约 64KB 的栈
    MOVQ	BX, g_stackguard0(DI)
    MOVQ	BX, g_stackguard1(DI)
    MOVQ	BX, (g_stack+stack_lo)(DI)
    MOVQ	SP, (g_stack+stack_hi)(DI)
    
	LEAQ	runtime·g0(SB), CX  // 把 g0 的地址存入 CX 寄存器
	MOVQ	CX, g(BX)           // 把 g0 的地址保存在线程本地存储里面
	LEAQ	runtime·m0(SB), AX  // 把 m0 的地址存入 AX 寄存器
	
	MOVQ	CX, m_g0(AX)        // 关联 m0 与 g0: m.g0 = g0 
	MOVQ	AX, g_m(CX)         // 关联 go 与 m0: g0.m = m0
    
    MOVL	24(SP), AX		    // 把函数参数个数 argc 写入 AX 寄存器
    MOVL	AX, 0(SP)           // argc 写入栈顶
    MOVQ	32(SP), AX		    // 把函数及参数地址 argv 写入 AX 寄存器
    MOVQ	AX, 8(SP)           // argv 写入栈
    
    CALL	runtime·args(SB)      // 命令行参数
    CALL	runtime·osinit(SB)    // 获取 CPU 核心数和内存物理页大小
    CALL	runtime·schedinit(SB) // 初始化 P
    
    // runtime/proc.go/main()
    MOVQ	$runtime·mainPC(SB), AX		// entry
    PUSHQ	AX
    // 创建 G 执行 runtime/proc.go/main()，这个 G 叫 main goroutine
    CALL	runtime·newproc(SB)
    POPQ	AX
    
    // 启动 M 运行上一步创建的 main goroutine
    CALL	runtime·mstart(SB)
    
    // 上面的 main 函数正常情况下会一直执行，不会走到这里。如果走到这里说明 main crash 了，这里 abort
    CALL	runtime·abort(SB)	// mstart should never return
    RET
```



`runtime.main()`:

```go
// runtime/proc.go

// go:linkname main_main main.main
// 链接到我们写的 main.go/main 函数
func main_main()

func main() {
    // 新建 sysmon 线程
    systemstack(func() {
			  newm(sysmon, nil, -1) 
		})
  
    // 初始化 GC
    gcenable()
  
    // 执行我们写的 main.go/main() 函数
    fn := main_main 
    fn()
}
```



`runtime.mstart()`:

```go
// runtime/proc.go

// = mstart()
func mstart0() {
    mstart1()
}

// 启动调度
func mstart1(){
    schedule()
}
```





# 调度函数 schedule()

`schedule()` 函数会暂停当前 `G`，取下个 `G` 执行。总体思路是：依次从 `P` 的本地 `G` 队列、全局 `G` 队列取 `G`：

1. 调度器每调度 `61` 次，从全局队列里取一次 `G`（以避免全局队列里有的 `G` 始终不被取出、饿死）
2. 调用 `runqget` 函数从 `P` 本地的运行队列中查找待执行的 `G`
3. 调用 `findrunnable` 函数从其他地方取 `G`（依次从本地队列、全局队列、netpoll、从其他 `P` 里偷窃取 `G`）
   - 先再次尝试从本地队列获取 `G`
   - 去全局队列获取（因为前面仅仅是1/61的概率）
   - 执行 `netpoll`，检查是否有 `IO` 就绪的 `G`
   - 如果还是没有，那么随机选择一个 `P`，偷其 `runqueue` 里的一半到自己的队列里
     - 这里的随机用到了一种质数算法，保证既随机，每个 `P` 又都能被访问到
     - 偷窃前会将 `M` 的自旋状态设为 `true`，偷窃后再改回去
     - 如果多次尝试偷 `P` 都失败了，`M` 会把 `P` 放回 `sched` 的 空闲 `P` 数组，自身休眠（放回空闲 `M` 列表）
4. `wakep`, 另一种情况是，`M` 太忙了，如果 `P` 池子里有空闲的 `P`，会唤醒其他 `sleep` 状态的 `M` 一起干活。如果没有 `sleep` 状态的 `M`，`runtime` 会新建一个 `M`。
5. `execute`，执行代码。



#### schedule

```go
// runtime/proc.go
// 找出一个 G 来执行
func schedule() {

// STW检查
top:
    if sched.gcwaiting != 0 {
        gcstopm()
        goto top
    }

    // 检查定时器
    checkTimers(pp, 0)
  
    // 进入 GC MarkWorker 工作模式
    if gp == nil && gcBlackenEnabled != 0 {
        gp = gcController.findRunnableGCWorker(_g_.m.p.ptr())
        if gp != nil {
            tryWakeP = true
        }
    }
  
    // 每 tick 61次，从全局队列里取 G
    if gp == nil {
        if _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {
            lock(&sched.lock)
            gp = globrunqget(_g_.m.p.ptr(), 1)
            unlock(&sched.lock)
        }
    }

    // 从本地队列里取 G，优先使用 P.runnext 字段
    if gp == nil {
        gp, inheritTime = runqget(_g_.m.p.ptr())
    }
    
    // 通过 findrunnable 函数从其他可能得地方寻找可执行 G
    if gp == nil {
        gp, inheritTime = findrunnable() // blocks until work is available
    }
    
  
    // 执行任务函数 
    execute(gp, inheritTime)
}
```



#### findrunnable

依次从 本地队列、全局队列、netpoll、其他 `P` 获取可运行的 `G`。偷窃优先级最低，因为会影响其他 `P` 执行（需要加锁）。

```go
// 寻找可执行的 G
// Tries to steal from other P's, get g from local or global queue, poll network.
func findrunnable() (gp *g, inheritTime bool) {
    now, pollUntil, _ := checkTimers(_p_, 0) // 检查 P 中的定时器，参考 Timer 的实现那篇文章
    // 本地队列
    if gp, inheritTime := runqget(_p_); gp != nil {
        return gp, inheritTime
    }

    // 本地队列里没G，从全局队列里取
    if sched.runqsize != 0 {
        lock(&sched.lock)          // 全局队列需要加锁        
        gp := globrunqget(_p_, 0)  // 从全局队列队头弹出；另外会分一部分 G 给当前 P
        unlock(&sched.lock)
        if gp != nil {
            return gp, false
        }
    }
  
    // 网络协程
    if netpollinited() && atomic.Load(&netpollWaiters) > 0 && atomic.Load64(&sched.lastpoll) != 0 {
        // 略
    }

    // 从其他 P 偷窃
    for i := 0; i < 4; i++ {
        // 这里的随机用到了一种质数算法，保证既随机，每个P又都能被访问到
        for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() {
            stealRunNextG := i > 2 // first look for ready queues with more than 1 g
            p2 := allp[enum.position()]
            if gp := runqsteal(_p_, p2, stealRunNextG); gp != nil {
                return gp, false
            }
        }
    } 
}
```



#### globrunqget

在检查全局队列时，除返回一个可用 `G` 外，还会批量转移一批 `G` 到 `P` 的本地队列。毕竟不能每次加锁去操作全局队列。

```go
// 从全局队列列取 G
// 另外还会分一部分 G 给 P（分的 G 个数为 Min（全局队列长度/P个，或者P本地队列/2））
func globrunqget(_p_ *p, max int32) *g {
    if sched.runqsize == 0 {
        return nil
    }

    // 分给 P 的 G 个数为（全局队列长度/P个数，P本地队列长度/2，二者最小值）
    // 将全局队列按 P 个数等分
    n := sched.runqsize/gomaxprocs + 1
    if n > sched.runqsize {
        n = sched.runqsize
    }
    // 不能超过 runq 数组长度的一半
    if n > int32(len(_p_.runq))/2 {
        n = int32(len(_p_.runq)) / 2
    }

    sched.runqsize -= n    // 调整计数

    gp := sched.runq.pop() // 从全局队列头部弹出 G
    n--
    for ; n > 0; n-- {     // 分 n 个 G 到当前 P 的本地队列
        gp1 := sched.runq.pop()
        runqput(_p_, gp1, false)
    }
    return gp
}
```



# 调度时机

- 新建 `M` 后，`mstart` 里触发 `schedule()`
- 新建 `G` 后，协程执行完毕退出时的 `goexit0()` 函数里触发 `schedule()` 
- `channel` 这种会通过 `gopark()` 挂起协程的函数，在使用 `gopark()` 休眠协程后会触发 `schedule()`
- 阻塞性系统调用，比如文件 IO，网络IO
  - `Golang` 重写了所有系统调用，封装了 `syscall` ，在其前后增加了 `entersyscall` 和 `exitsyscall`，进入系统调用前暂停当前协程、完成系统调用后在 `exitsyscall()` 里恢复其资源、进度，并触发 `schedule()`
- `sysmon` 会定期检查运行超过 `10ms` 的任务，进行调度
- 主动调用 `runtime.Gosched()`，这个很少见，一般调试才用

#### Gosched

用户可以通过在代码里调用 `runtime.Gosched()` 来触发调度。该函数可将当前 `G` 任务暂停，放回全局队列等待调度，让出当前 `M` 去执行其他任务。

```go
// runtime/proc.go
func Gosched() {
  	mcall(gosched_m)
}

// mcall 主要做三件事：
// 1. 保存当前 G 状态，将 SP、PC 寄存器等保存到 G.sched 区域
// 2. 切换到 g0
// 3. 执行 fn
func mcall(fn func(*g))

func gosched_m(gp *g) {
    goschedImpl(gp)
}

func goschedImpl(gp *g) {
    casgstatus(gp, _Grunning, _Grunnable) // 修改 G 的状态为 Grunnable
    dropg()                               // 解绑 M 和 G
    lock(&sched.lock)
    globrunqput(gp)                       // 将 G 放入全局队列
    unlock(&sched.lock)

    schedule()                            // 调度
}
```



#### gopark

与 `Gosched()` 最大的区别在于，少了将 `G` 放回全局队列这步。必须主动调用 `goready()` 恢复运行，否则该任务会遗失。

`goready` 会直接将 `G` 放回 `P.runnext`，使之以最高优先级恢复运行。

```go
// runtime/proc.go
func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {
    mcall(park_m)
}

func park_m(gp *g) {
    _g_ := getg()

    casgstatus(gp, _Grunning, _Gwaiting) 
    dropg()     // 解绑 M 和 G

    schedule()
}
```



#### goready

当通过 `gopark()` 休眠的协程满足条件、可以唤醒后（比如从 `channel` 中收到了数据），运行时会调用 `goready()` 唤醒协程

```go
// runtime/proc.go
func goready(gp *g, traceskip int) {
    systemstack(func() {
        ready(gp, traceskip, true)
    })
}

func ready(gp *g, traceskip int, next bool) {
    _g_ := getg()

    casgstatus(gp, _Gwaiting, _Grunnable)
    runqput(_g_.m.p.ptr(), gp, next)
    if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 {
        wakep()
    }
}

func wakep() {
    startm(nil, true) // 找一个 M 执行 P 的协程
}
```





#### stopTheWorld

在 `GC` 时，用户逻辑必须暂停在一个安全点上，否则会引发很多意外问题。STW 通过通知机制，让 `G` 主动停止。比如，设置 `gcwaiting=1` ，再执行调度函数 `schedule()` 休眠 `M`；向所有 `P` 里正在运行的 `G` 发出抢占调度信号，使其暂停。

```go
// runtime/proc1.go
func stopTheWorld(reason string) {
      semacquire(&worldsema)     // CAS加锁，其它执行STW的函数会阻塞住
      gp := getg()
      systemstack(func() {
            casgstatus(gp, _Grunning, _Gwaiting)  // 设置当前 G 状态为 waiting
            stopTheWorldWithSema()                // 实际STW函数
            casgstatus(gp, _Gwaiting, _Grunning)  // 恢复 G 状态
    })
}

func stopTheWorldWithSema() {
    _g_ := getg()

    lock(&sched.lock)
    sched.stopwait = gomaxprocs        // 需要暂停的 P 的计数
    atomic.Store(&sched.gcwaiting, 1)  // 设置停止标志，schedule 之类的函数会检查这个标志，主动休眠 M
    preemptall()                       // 向所有正在运行的 G 发出抢占调度
    
    _g_.m.p.ptr().status = _Pgcstop    // 暂停当前 P
    sched.stopwait--
    
    // 暂停所有 syscall 状态的 P
    for _, p := range allp {                                      // 遍历全局 P 数组
        s := p.status
        if s == _Psyscall && atomic.Cas(&p.status, s, _Pgcstop) { // 其实就是改了下 P 的状态为 gcstop 
            p.syscalltick++
            sched.stopwait--
        }
    }

    // 暂停空闲 P
    for {
        p := pidleget()
        if p == nil {
            break
        }
        p.status = _Pgcstop // 也是更新状态
        sched.stopwait--
    }
    wait := sched.stopwait > 0
    unlock(&sched.lock)

    // 如果还有 P 没暂停，这里会一直休眠 - 重试调度
    if wait {
        for {
            // wait for 100us, then try to re-preempt in case of any races
            if notetsleep(&sched.stopnote, 100*1000) {
                noteclear(&sched.stopnote)
                break
            }
            preemptall()
        }
    }
}
```







# 优点

- 调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换
- 不需要频繁的进行内存的分配与释放。在用户态维护着一块大的内存池， 不直接调用系统的 `malloc` 函数（除非内存池需要改变）
- 另一方面充分利用了多核的硬件资源，近似的把若干 `goroutine` 均分在物理线程上
- 再加上本身 `goroutine` 的超轻量，以上种种保证了 `go` 调度方面的性能





# 参考

[主 goroutine 如何创建（里面有非常详细的汇编解析）](https://golang.design/go-questions/sched/main-goroutine/)
